{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22d1a480-3670-43d9-a602-5a60ed264a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape: (32561, 15)\n",
      "   age         workclass  fnlwgt  education  education-num  \\\n",
      "0   39         State-gov   77516  Bachelors             13   \n",
      "1   50  Self-emp-not-inc   83311  Bachelors             13   \n",
      "2   38           Private  215646    HS-grad              9   \n",
      "3   53           Private  234721       11th              7   \n",
      "4   28           Private  338409  Bachelors             13   \n",
      "\n",
      "       marital-status         occupation   relationship   race     sex  \\\n",
      "0       Never-married       Adm-clerical  Not-in-family  White    Male   \n",
      "1  Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
      "2            Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
      "3  Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
      "4  Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
      "\n",
      "   capital-gain  capital-loss  hours-per-week native-country income  \n",
      "0          2174             0              40  United-States  <=50K  \n",
      "1             0             0              13  United-States  <=50K  \n",
      "2             0             0              40  United-States  <=50K  \n",
      "3             0             0              40  United-States  <=50K  \n",
      "4             0             0              40           Cuba  <=50K  \n",
      "After dropping missing values: (32561, 15)\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.94      0.89      4942\n",
      "           1       0.72      0.46      0.56      1571\n",
      "\n",
      "    accuracy                           0.83      6513\n",
      "   macro avg       0.78      0.70      0.73      6513\n",
      "weighted avg       0.81      0.83      0.81      6513\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../model/preprocess.pkl']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Adult Income Prediction - Data Cleaning and Model Training\n",
    "# -----------------------------------------------------------------------------\n",
    "# This notebook demonstrates how to load the Adult Income dataset from UCI,\n",
    "# preprocess it, train a logistic regression model, and save the model and\n",
    "# preprocessing pipeline for later deployment using Flask.\n",
    "#\n",
    "# Dataset Source:\n",
    "# https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\n",
    "#\n",
    "# The goal is to predict whether an individual earns more than $50K/year\n",
    "# based on demographic and employment data.\n",
    "# =============================================================================\n",
    "\n",
    "# --- Import required libraries ---\n",
    "import pandas as pd                  # For data manipulation\n",
    "import numpy as np                   # For numerical operations\n",
    "from sklearn.model_selection import train_test_split  # To split the dataset\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler  # For encoding and scaling\n",
    "from sklearn.linear_model import LogisticRegression    # ML model\n",
    "from sklearn.metrics import classification_report      # Model evaluation\n",
    "import joblib                        # For saving model and preprocessing pipeline\n",
    "\n",
    "# --- Load the dataset from UCI repository ---\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\"\n",
    "\n",
    "# List of column names based on the dataset documentation\n",
    "column_names = [\n",
    "    \"age\", \"workclass\", \"fnlwgt\", \"education\", \"education-num\", \n",
    "    \"marital-status\", \"occupation\", \"relationship\", \"race\", \n",
    "    \"sex\", \"capital-gain\", \"capital-loss\", \"hours-per-week\", \n",
    "    \"native-country\", \"income\"\n",
    "]\n",
    "\n",
    "# Load the dataset with column names and handle missing values\n",
    "# \" ?\" is used in the dataset to represent missing data\n",
    "df = pd.read_csv(url, names=column_names, na_values=\" ?\", skipinitialspace=True)\n",
    "\n",
    "# Display the shape and the first few rows of the dataset\n",
    "print(\"Dataset Shape:\", df.shape)\n",
    "print(df.head())\n",
    "\n",
    "# --- Drop rows with missing values ---\n",
    "# Note: You can also use imputation instead of dropping, but this is simpler for now\n",
    "df.dropna(inplace=True)\n",
    "print(\"After dropping missing values:\", df.shape)\n",
    "\n",
    "# --- Encode categorical variables using Label Encoding ---\n",
    "# This converts string labels into numeric values\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "\n",
    "label_encoders = {}  # To save encoders for each column (used later in deployment)\n",
    "\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# --- Separate features (X) and target label (y) ---\n",
    "X = df.drop([\"income\", \"fnlwgt\"], axis=1)  # All columns except 'income' and 'fnlwgt'\n",
    "y = df[\"income\"]               # Target variable (0 or 1)\n",
    "\n",
    "# --- Feature Scaling ---\n",
    "# Standardize features to have zero mean and unit variance\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# --- Split the dataset into training and testing sets ---\n",
    "# 80% for training, 20% for testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# --- Train the Model ---\n",
    "# Using Logistic Regression for binary classification\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# --- Model Evaluation ---\n",
    "# Predict on test data and print classification report\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Classification Report:\\n\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# --- Save the Trained Model and Scaler for Deployment ---\n",
    "# These will be used later in the Flask app to make live predictions\n",
    "\n",
    "# Save model\n",
    "joblib.dump(model, \"../model/model.pkl\")\n",
    "\n",
    "# Save scaler\n",
    "joblib.dump(scaler, \"../model/preprocess.pkl\")\n",
    "\n",
    "# Note: If needed, you could also save the label_encoders dictionary\n",
    "# using joblib or pickle for full reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a864d0ac-521c-45f1-a7dc-8655e34ce382",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
